import base64
import cv2
import numpy as np
import json
import os
from openai import OpenAI

# ========== é…ç½® ==========
openai_api_key = os.environ.get("OPENAI_API_KEY")
client = OpenAI(
    api_key=openai_api_key,
    base_url="https://dashscope.aliyuncs.com/compatible-mode/v1",
)

IMAGE_SIZE = (256, 256)  # å›ºå®šå°ºå¯¸

# ========== å·¥å…·å‡½æ•° ==========


def encode_image(image_path):
    with open(image_path, "rb") as f:
        return base64.b64encode(f.read()).decode()


def call_mllm_find_bbox(original_img_path, generated_img_path):
    base64_orig = encode_image(original_img_path)
    base64_gen = encode_image(generated_img_path)

    prompt = """
ä½ æ˜¯ä¸€ä½ç»éªŒä¸°å¯Œçš„çš®é©è´¨é‡æ£€æµ‹å‘˜ï¼Œè¯·å¯¹æ¯”ä»¥ä¸‹ä¸¤å¼  256x256 çš„çš®é©å›¾åƒï¼š

- ç¬¬ä¸€å¼ å›¾åƒæ˜¯åŸå§‹ã€æ— ç¼ºé™·çš„çš®é©å›¾ï¼›
- ç¬¬äºŒå¼ å›¾åƒæ˜¯é€šè¿‡ GAN ç”Ÿæˆçš„çš®é©å›¾ï¼Œå¯èƒ½å­˜åœ¨ä»¥ä¸‹ç¼ºé™·ç±»å‹ï¼š
  - å±€éƒ¨çº¹ç†é‡å¤ï¼ˆå¦‚ç›¸é‚»åŒºåŸŸå‡ºç°ç±»ä¼¼çš„èŠ±çº¹å—ï¼‰
  - å±€éƒ¨é¢œè‰²å¼‚å¸¸ï¼ˆè‰²å—åæš—ã€åäº®æˆ–é¢œè‰²å¤±çœŸï¼‰
  - å±€éƒ¨ç»“æ„æ‰­æ›²ï¼ˆå½¢çŠ¶å¼‚å¸¸æˆ–è¾¹ç¼˜æ¨¡ç³Šï¼‰
  - å°èŒƒå›´å­”æ´æˆ–è£‚çº¹
  - è½»å¾®çš„å™ªç‚¹æˆ–ä¼ªå½±

è¯·ä½ ï¼š
1. åªæ ‡è®°é‚£äº›æ˜æ˜¾ä¸”å±€éƒ¨çš„ç¼ºé™·åŒºåŸŸï¼Œå¿½ç•¥æ•´ä½“è½»å¾®å·®å¼‚ï¼›
2. ä¸è¦æŠŠçš®é©çš„è‡ªç„¶çº¹ç†æˆ–æ­£å¸¸è‰²å·®è¯¯åˆ¤ä¸ºç¼ºé™·ï¼›
3. è¿”å›ç¼ºé™·åŒºåŸŸçš„çŸ©å½¢æ¡†ï¼ˆbboxï¼‰å’Œç®€çŸ­è¯´æ˜ï¼›
4. å¦‚æœæ²¡æœ‰ç¼ºé™·ï¼Œè¿”å›ç©ºæ•°ç»„ `[]`ï¼›
5. æ‰€æœ‰åæ ‡éƒ½åœ¨ `[0,256)` å†…ï¼Œæ•´æ•°ã€‚

âš ï¸ ä»…è¿”å›ä¸¥æ ¼çš„ JSON æ ¼å¼ï¼š

```json
[
  {"bbox": [x1, y1, x2, y2], "reason": "ç®€çŸ­æè¿°ç¼ºé™·"},
  ...
]


    """

    print("ğŸš€ è°ƒç”¨ å¤šæ¨¡æ€ å¼€å§‹åˆ†æå›¾åƒå·®å¼‚...")

    response = client.chat.completions.create(
        model="qwen-vl-max-latest",
        messages=[
            {
                "role": "user",
                "content": [
                    {"type": "text", "text": prompt},
                    {
                        "type": "image_url",
                        "image_url": {"url": f"data:image/png;base64,{base64_orig}"},
                    },
                    {
                        "type": "image_url",
                        "image_url": {"url": f"data:image/png;base64,{base64_gen}"},
                    },
                ],
            }
        ],
        temperature=0.2,
        max_tokens=1000,
    )

    content = response.choices[0].message.content.strip()
    print("ğŸ§  MLLM è¿”å›å†…å®¹ï¼š\n", content)

    content = content.replace("```json", "").replace("```", "")

    try:
        bbox_data = json.loads(content)
        return bbox_data
    except json.JSONDecodeError:
        print("âš ï¸ æ— æ³•è§£æ GPT è¿”å›çš„ JSONï¼Œè¯·æ£€æŸ¥æ ¼å¼")
        return []


def generate_mask_from_bboxes(image_size, bbox_json, mask_path="mask.png"):
    print(f"ğŸš€ ç”Ÿæˆ mask {bbox_json}")
    mask = np.zeros(image_size, dtype=np.uint8)
    for item in bbox_json:
        x1, y1, x2, y2 = item["bbox"]
        cv2.rectangle(mask, (x1, y1), (x2, y2), 255, -1)
    cv2.imwrite(mask_path, mask)
    print(f"âœ… ä¿å­˜ mask åˆ°ï¼š{mask_path}")
    return mask


# ========== ä¸»æµç¨‹ ==========


def run(original_img_path, generated_img_path, output_mask_path="mask.png"):
    bbox_data = call_mllm_find_bbox(original_img_path, generated_img_path)
    if not bbox_data:
        print("âŒ æ— æ³•è·å–æœ‰æ•ˆçš„ bboxï¼Œç»ˆæ­¢ã€‚")
        return
    generate_mask_from_bboxes(IMAGE_SIZE, bbox_data, output_mask_path)


# ========== ç¤ºä¾‹è°ƒç”¨ ==========
if __name__ == "__main__":
    run(
        r"D:/github_repo/auto_ml/ai_platform/gan/good/0.png",
        r"D:\github_repo\auto_ml\ai_platform\augment\simple_gan\fake_sample_1.png",
        "mask.png",
    )
